# ğŸ¤– Guide de l'Autocritique de l'IA

## Vue d'ensemble

Le systÃ¨me d'autocritique permet Ã  l'IA de traduction d'analyser ses propres performances et de gÃ©nÃ©rer des rapports dÃ©taillÃ©s indiquant :
- âœ… **Ce qu'elle fait bien** (points forts)
- âŒ **Ce qu'elle fait mal** (points faibles)
- ğŸ’¡ **Comment s'amÃ©liorer** (recommandations)

## ğŸš€ Utilisation

### GÃ©nÃ©rer un rapport d'autocritique

```bash
make ml-self-critique
```

Ou directement :

```bash
cd backend
node scripts/ml_self_critique.js
```

## ğŸ“Š Ce que le rapport analyse

### 1. Rapports de test existants
- Analyse les 10 derniers rapports de test
- Calcule la prÃ©cision moyenne
- Identifie les erreurs par type (ingrÃ©dients, instructions, unitÃ©s)
- DÃ©tecte les tendances de performance

### 2. Feedbacks utilisateur
- Analyse tous les feedbacks enregistrÃ©s
- Identifie les erreurs les plus frÃ©quentes
- DÃ©tecte les patterns d'erreurs rÃ©currents
- Analyse les langues les plus problÃ©matiques

### 3. Performance par type
- Ã‰value la couverture de chaque type de traduction
- Identifie les types bien/mal couverts
- Compare les performances franÃ§ais/espagnol

## ğŸ“‹ Structure du rapport

Le rapport d'autocritique contient :

### Vue d'ensemble
- PrÃ©cision moyenne
- Nombre total de tests
- Nombre total de feedbacks

### Points forts âœ…
- PrÃ©cision Ã©levÃ©e
- Large base de connaissances
- Types bien couverts
- Beaucoup de feedbacks approuvÃ©s

### Points faibles âŒ
- PrÃ©cision faible
- Traductions manquantes
- Types mal couverts
- Erreurs frÃ©quentes
- Feedbacks en attente
- Erreurs rÃ©currentes non corrigÃ©es

### Recommandations ğŸ’¡
- PrioritÃ© haute : Actions urgentes Ã  prendre
- PrioritÃ© moyenne : AmÃ©liorations importantes
- PrioritÃ© basse : Optimisations Ã  long terme

## ğŸ“ Fichiers gÃ©nÃ©rÃ©s

Les rapports sont sauvegardÃ©s dans `backend/data/ml_critiques/` :

- `self_critique_YYYY-MM-DDTHH-MM-SS.json` - Rapport avec timestamp
- `latest_self_critique.json` - Dernier rapport gÃ©nÃ©rÃ©

## ğŸ” Exemple de rapport

```json
{
  "timestamp": "2025-12-10T23:30:00.000Z",
  "overall": {
    "accuracy": 75.5,
    "totalTests": 1423,
    "totalFeedbacks": 250
  },
  "strengths": [
    {
      "category": "PrÃ©cision",
      "description": "PrÃ©cision correcte de 75.5%",
      "evidence": "1074 traductions correctes sur 1423 testÃ©es"
    }
  ],
  "weaknesses": [
    {
      "category": "Couverture",
      "description": "Beaucoup de traductions manquantes (698)",
      "evidence": "L'IA ne trouve pas de traduction pour de nombreux mots",
      "impact": "Fallback vers LibreTranslate trop frÃ©quent"
    }
  ],
  "recommendations": [
    {
      "priority": "haute",
      "action": "Enrichir le modÃ¨le avec plus de traductions",
      "reason": "698 traductions manquantes dÃ©tectÃ©es",
      "steps": [
        "Ajouter des traductions pour les mots les plus frÃ©quents",
        "Valider les feedbacks utilisateur",
        "Utiliser les dictionnaires culinaires existants"
      ]
    }
  ]
}
```

## ğŸ’¡ Utilisation recommandÃ©e

### FrÃ©quence
- **Quotidienne** : Pour suivre l'Ã©volution des performances
- **AprÃ¨s chaque test** : Pour analyser les rÃ©sultats immÃ©diatement
- **Avant un rÃ©entraÃ®nement** : Pour identifier les prioritÃ©s

### Workflow suggÃ©rÃ©

1. **GÃ©nÃ©rer le rapport d'autocritique**
   ```bash
   make ml-self-critique
   ```

2. **Lire les recommandations prioritaires**
   - Commencer par les actions de prioritÃ© "haute"
   - Suivre les Ã©tapes suggÃ©rÃ©es

3. **Appliquer les corrections**
   - Valider les feedbacks en attente
   - RÃ©entraÃ®ner le modÃ¨le si nÃ©cessaire
   - Ajouter des traductions manquantes

4. **VÃ©rifier l'amÃ©lioration**
   - Relancer un test : `make test-ml-lab`
   - RegÃ©nÃ©rer l'autocritique pour voir les progrÃ¨s

## ğŸ¯ InterprÃ©tation des rÃ©sultats

### PrÃ©cision
- **â‰¥ 80%** : Excellente performance âœ…
- **60-80%** : Performance correcte âš ï¸
- **< 60%** : Performance faible âŒ

### Couverture
- **â‰¥ 500 traductions** : Large base de connaissances âœ…
- **100-500 traductions** : Base correcte âš ï¸
- **< 100 traductions** : Base insuffisante âŒ

### Feedbacks
- **Beaucoup d'approuvÃ©s** : L'IA apprend bien âœ…
- **Beaucoup en attente** : Besoin de validation âš ï¸
- **Beaucoup de rejetÃ©s** : QualitÃ© des feedbacks Ã  amÃ©liorer âŒ

## ğŸ”„ IntÃ©gration avec les autres outils

L'autocritique s'intÃ¨gre avec :

- **`make test-ml-lab`** : GÃ©nÃ¨re les donnÃ©es de test analysÃ©es
- **`make ml-metrics`** : ComplÃ¨te les mÃ©triques avec l'analyse critique
- **`make retrain-ml`** : Utilise les recommandations pour amÃ©liorer le modÃ¨le
- **`make validate-ml-auto`** : Valide les feedbacks identifiÃ©s comme importants

## ğŸ“ Notes importantes

- Le rapport analyse les **10 derniers rapports de test** pour Ã©viter de surcharger
- Les **feedbacks en attente** sont identifiÃ©s comme une faiblesse car ils ne sont pas utilisÃ©s pour l'entraÃ®nement
- Les **erreurs rÃ©currentes** sont prioritaires car elles impactent plusieurs utilisateurs
- Le rapport est **objectif** et basÃ© uniquement sur les donnÃ©es disponibles

## ğŸš¨ Actions urgentes

Si le rapport indique :
- **PrÃ©cision < 50%** : RÃ©entraÃ®ner immÃ©diatement le modÃ¨le
- **> 100 traductions manquantes** : Enrichir le modÃ¨le en prioritÃ©
- **Erreurs rÃ©currentes** : Corriger les traductions problÃ©matiques
- **> 50 feedbacks en attente** : Valider les feedbacks rapidement

